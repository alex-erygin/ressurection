{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.chat_models.gigachat import GigaChat\n",
    "\n",
    "model = GigaChat(\n",
    "    credentials=\"\",\n",
    "    scope=\"GIGACHAT_API_PERS\",\n",
    "    model=\"GigaChat-Pro\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import (\n",
    "    BaseChatMessageHistory,\n",
    "    InMemoryChatMessageHistory,\n",
    ")\n",
    "\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NotImplementedError in RootListenersTracer.on_llm_end callback: NotImplementedError(\"Trying to load an object that doesn't implement serialization: {'lc': 1, 'type': 'not_implemented', 'id': ['gigachat', 'models', 'usage', 'Usage'], 'repr': 'Usage(prompt_tokens=20, completion_tokens=31, total_tokens=51)'}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Здравствуйте, Либерий! Я генеративная языковая модель, могу с вами пообщаться. Расскажите немного о себе.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.messages import AIMessage\n",
    "config = {\"configurable\": {\"session_id\": \"abc2\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Привет! Меня зоут Либерий!\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NotImplementedError in RootListenersTracer.on_llm_end callback: NotImplementedError(\"Trying to load an object that doesn't implement serialization: {'lc': 1, 'type': 'not_implemented', 'id': ['gigachat', 'models', 'usage', 'Usage'], 'repr': 'Usage(prompt_tokens=16, completion_tokens=38, total_tokens=54)'}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Я не могу знать вашего имени, но, судя по данным моего последнего обновления, вас зовут Александр. Если это не так, пожалуйста, сообщите мне ваше имя.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Как меня зовут?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Вас зовут Вася.', response_metadata={'token_usage': Usage(prompt_tokens=60, completion_tokens=8, total_tokens=68), 'model_name': 'GigaChat-Pro:2.2.25.3', 'finish_reason': 'stop'}, id='run-7f720621-bfa8-4c82-a3b0-95458390834e-0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Привет! Меня зовут Вася\"),\n",
    "        AIMessage(\n",
    "            content=\"Здравствуйте, Вася! Я генеративная языковая модель от Сбера. Готова ответить на ваши вопросы.\"\n",
    "        ),\n",
    "        HumanMessage(content=\"Как меня зовут?\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Ты личный помощник. Старайся как можно лучше помочь пользователю.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Здравствуйте, Вася! Рада знакомству. Как я могу вам помочь?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"messages\": [HumanMessage(content=\"Привет! Меня зовут Вася\")]})\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Здравствуйте, Кира! Рада знакомству с вами.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history)\n",
    "config = {\"configurable\": {\"session_id\": \"abc5\"}}\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Привет! Меня зовут Кира\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Вас зовут Кира.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Как меня зовут?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Ты — личный ассистент. Старайся как можно лучше помочь пользователю. Отвечай на все вопросы пользователя на следующем языке: {language}. Не называй своего имени.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, I am your personal assistant. How can I help you?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"Привет! Меня зовут Вася\")],\n",
    "        \"language\": \"Английский\",\n",
    "    }\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Николай.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"abc15\"}}\n",
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"Привет! Меня зовут Коля\")],\n",
    "        \"language\": \"Английский\",\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"Назови мое имя!\")],\n",
    "        \"language\": \"Английский\",\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Ты — личный ассистент'),\n",
       " HumanMessage(content='Сколько будет 2 + 2'),\n",
       " AIMessage(content='4'),\n",
       " HumanMessage(content='Спасибо'),\n",
       " AIMessage(content='Пожалуйста!'),\n",
       " HumanMessage(content='Тебе нравится наш разговор?'),\n",
       " AIMessage(content='Да!')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=30,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\",\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"Ты — личный ассистент\"),\n",
    "    HumanMessage(content=\"Привет! Меня зовут Вася\"),\n",
    "    AIMessage(content=\"Привет!\"),\n",
    "    HumanMessage(content=\"Я люблю шоколадное мороженое\"),\n",
    "    AIMessage(content=\"Здорово\"),\n",
    "    HumanMessage(content=\"Сколько будет 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"Спасибо\"),\n",
    "    AIMessage(content=\"Пожалуйста!\"),\n",
    "    HumanMessage(content=\"Тебе нравится наш разговор?\"),\n",
    "    AIMessage(content=\"Да!\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Однажды в лесу родился маленький зайчик. Он был очень любопытный и постоянно бегал вокруг своей мамы, заглядывая ей в глаза. Однажды мама-зайчиха сказала ему: «Вася, не бегай так быстро, а то упадешь!» Но Вася не послушал её и продолжал бегать. И вот однажды он упал и сломал себе лапку|.| С| тех| пор| он| стал| очень| о|сто|рож|ным| и| больше| не| бе|гал| так| быстро|.||"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"abc19\"}}\n",
    "for r in with_message_history.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"Привет! Я Вася. Расскажи историю из 100 слов\")\n",
    "        ],\n",
    "        \"language\": \"русский\",\n",
    "    },\n",
    "    config=config,\n",
    "):\n",
    "    \n",
    "    print(r.content, end=\"|\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
